{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc46a9b-8275-4af1-b41c-50bb715ddee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog=r\"C:\\Users\\madhu\\OneDrive\\Documents\\Madhu's pri folder\\ML_projects\\Miniproject_part 2\\cat_dogs\\PetImages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f3e830-86aa-40b5-a79d-5f628a9a96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "cat_folder = r\"C:\\Users\\madhu\\OneDrive\\Documents\\Madhu's pri folder\\ML_projects\\Miniproject_part 2\\cat_dogs\\PetImages\\Cat\"\n",
    "dog_folder = r\"C:\\Users\\madhu\\OneDrive\\Documents\\Madhu's pri folder\\ML_projects\\Miniproject_part 2\\cat_dogs\\PetImages\\Dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df833b5-2f35-4602-bd0b-c65385629450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24999 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator instance for data preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Use the flow_from_directory method to load and resize images\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    cat_dog,  # Directory containing subdirectories of 'cats' and 'dogs'\n",
    "    target_size=(128, 128),  # Resize all images to 128x128\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # For multi-class classification (cat vs dog)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbb8f2-4a2b-4af3-b783-f728e393e026",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7877323-2150-45c6-b5c0-9a87971d77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of single image normalization\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from PIL import Image\n",
    "\n",
    "# Load an image (replace 'path_to_image.jpg' with your image file path)\n",
    "img = image.load_img( r\"C:\\Users\\madhu\\OneDrive\\Documents\\Madhu's pri folder\\ML_projects\\Miniproject_part 2\\cat_dogs\\PetImages\\Cat\\0.jpg\", target_size=(128, 128))\n",
    "\n",
    "# Convert to numpy array\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Normalize the pixel values between 0 and 1 (divide by 255)\n",
    "img_array = img_array / 255.0  # Values now in range [0, 1]\n",
    "\n",
    "# Alternatively, if you're using a pre-trained model like MobileNetV2\n",
    "# you can use the preprocess_input function to normalize the image\n",
    "#img_array = preprocess_input(img_array)  # This handles mean subtraction for MobileNetV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc09b5d-a57e-492c-8161-8eed3bacc6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260108d-1572-4630-aa8b-dd0dfc1df119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a474ae2-c37c-4d02-95e7-570d1d03e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "image_files = os.listdir(cat_folder)\n",
    "\n",
    "# Filter out non-image files if necessary\n",
    "image_files = [file for file in image_files if file.endswith(('jpg', 'jpeg', 'png', 'gif'))]\n",
    "\n",
    "# Print the list of image files\n",
    "print(image_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "453f218f-d015-4ade-94aa-6e6f392f5afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    img = image.load_img( img, target_size=(128, 128))\n",
    "\n",
    "# Convert to numpy array\n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "#Normalize the pixel values between 0 and 1 (divide by 255)\n",
    "    img_array = img_array / 255.0  # Values now in range [0, 1]\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3336d-9c75-4938-8b48-bfc31879fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiple image normalization: (cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d504779a-da92-4cc5-b1dc-66bf43c57056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Thumbs.db: cannot identify image file <_io.BytesIO object at 0x00000209AD54EBB0>\n",
      "[[[0.79607844 0.6431373  0.34117648]\n",
      "  [0.8156863  0.6627451  0.36078432]\n",
      "  [0.8235294  0.67058825 0.36862746]\n",
      "  ...\n",
      "  [0.9607843  0.8117647  0.49411765]\n",
      "  [0.95686275 0.79607844 0.4745098 ]\n",
      "  [0.9372549  0.78431374 0.4745098 ]]\n",
      "\n",
      " [[0.79607844 0.6431373  0.34117648]\n",
      "  [0.8156863  0.6627451  0.36078432]\n",
      "  [0.8235294  0.67058825 0.36862746]\n",
      "  ...\n",
      "  [0.9607843  0.8156863  0.49803922]\n",
      "  [0.9529412  0.8039216  0.47843137]\n",
      "  [0.9411765  0.7882353  0.47843137]]\n",
      "\n",
      " [[0.79607844 0.6431373  0.34117648]\n",
      "  [0.8156863  0.6627451  0.36078432]\n",
      "  [0.8235294  0.67058825 0.36862746]\n",
      "  ...\n",
      "  [0.9647059  0.81960785 0.5058824 ]\n",
      "  [0.9529412  0.80784315 0.49019608]\n",
      "  [0.94509804 0.7921569  0.48235294]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.62352943 0.4862745  0.21960784]\n",
      "  [0.6313726  0.49411765 0.22745098]\n",
      "  [0.6313726  0.49411765 0.22745098]\n",
      "  ...\n",
      "  [0.01176471 0.01568628 0.        ]\n",
      "  [0.01176471 0.01568628 0.        ]\n",
      "  [0.00784314 0.01176471 0.        ]]\n",
      "\n",
      " [[0.6039216  0.48235294 0.21960784]\n",
      "  [0.6117647  0.49019608 0.22745098]\n",
      "  [0.61960787 0.49803922 0.23529412]\n",
      "  ...\n",
      "  [0.01176471 0.01176471 0.00392157]\n",
      "  [0.01176471 0.01176471 0.00392157]\n",
      "  [0.01176471 0.01176471 0.00392157]]\n",
      "\n",
      " [[0.59607846 0.4745098  0.21176471]\n",
      "  [0.6        0.47843137 0.21568628]\n",
      "  [0.6156863  0.49411765 0.23137255]\n",
      "  ...\n",
      "  [0.00392157 0.00392157 0.        ]\n",
      "  [0.00392157 0.00392157 0.        ]\n",
      "  [0.00392157 0.00392157 0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "valid_extensions = ('.jpg', '.jpeg', '.png')\n",
    "cat_images=[]\n",
    "faults_cat=0\n",
    "for img_name in os.listdir(cat_folder):\n",
    "    img_path = os.path.join(cat_folder, img_name)\n",
    "    try:\n",
    "        # Normalize the image\n",
    "        normalized_image = normalize(img_path)\n",
    "        cat_images.append(normalized_image)\n",
    "    \n",
    "    except Exception as e:\n",
    "        faults_cat=faults_cat+1\n",
    "        print(f\"Error processing {img_name}: {e}\")\n",
    "\n",
    "# Check the result\n",
    "if cat_images:\n",
    "    print(cat_images[0])\n",
    "else:\n",
    "    print(\"No valid images were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a41798e-8976-414d-b53e-59fb4f64e626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(faults_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c246111-df9f-4eea-b6f0-df8487fcdcfc",
   "metadata": {},
   "source": [
    "Multiple image normalization: (dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fbacdf1-1f26-4995-af96-fc9fb1b03317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 11702.jpg: cannot identify image file <_io.BytesIO object at 0x00000209AD54EA20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madhu\\anaconda3\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:870: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Thumbs.db: cannot identify image file <_io.BytesIO object at 0x00000209AD9F31A0>\n",
      "[[[0.45882353 0.4509804  0.49411765]\n",
      "  [0.42745098 0.41568628 0.48235294]\n",
      "  [0.44705883 0.4392157  0.49411765]\n",
      "  ...\n",
      "  [0.54901963 0.5568628  0.6039216 ]\n",
      "  [0.52156866 0.5294118  0.5764706 ]\n",
      "  [0.52156866 0.52156866 0.56078434]]\n",
      "\n",
      " [[0.47058824 0.4627451  0.5058824 ]\n",
      "  [0.44313726 0.43137255 0.49803922]\n",
      "  [0.45882353 0.4509804  0.5058824 ]\n",
      "  ...\n",
      "  [0.5529412  0.56078434 0.60784316]\n",
      "  [0.5372549  0.54509807 0.5921569 ]\n",
      "  [0.5372549  0.5372549  0.5764706 ]]\n",
      "\n",
      " [[0.48235294 0.4745098  0.5176471 ]\n",
      "  [0.4509804  0.4392157  0.5058824 ]\n",
      "  [0.4627451  0.45490196 0.50980395]\n",
      "  ...\n",
      "  [0.5568628  0.5647059  0.6117647 ]\n",
      "  [0.54901963 0.5568628  0.6039216 ]\n",
      "  [0.54901963 0.56078434 0.59607846]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.23921569 0.30980393 0.3254902 ]\n",
      "  [0.34117648 0.3529412  0.3882353 ]\n",
      "  [0.29803923 0.30980393 0.3372549 ]\n",
      "  ...\n",
      "  [0.2627451  0.29411766 0.30588236]\n",
      "  [0.21960784 0.2509804  0.2627451 ]\n",
      "  [0.2627451  0.29411766 0.30588236]]\n",
      "\n",
      " [[0.2627451  0.28235295 0.29803923]\n",
      "  [0.25490198 0.28627452 0.29803923]\n",
      "  [0.2509804  0.2901961  0.29803923]\n",
      "  ...\n",
      "  [0.25490198 0.28235295 0.3137255 ]\n",
      "  [0.23529412 0.2627451  0.29411766]\n",
      "  [0.30588236 0.3372549  0.34901962]]\n",
      "\n",
      " [[0.26666668 0.28627452 0.3019608 ]\n",
      "  [0.26666668 0.29803923 0.30980393]\n",
      "  [0.24313726 0.28235295 0.2901961 ]\n",
      "  ...\n",
      "  [0.28627452 0.3137255  0.34509805]\n",
      "  [0.32156864 0.34901962 0.38039216]\n",
      "  [0.2627451  0.29411766 0.30588236]]]\n"
     ]
    }
   ],
   "source": [
    "dog_images=[]\n",
    "faults_dog=0\n",
    "for img_name in os.listdir(dog_folder):\n",
    "    img_path = os.path.join(dog_folder, img_name)\n",
    "    try:\n",
    "        # Normalize the image\n",
    "        normalized_image = normalize(img_path)\n",
    "        dog_images.append(normalized_image)\n",
    "    \n",
    "    except Exception as e:\n",
    "        faults_dog=faults_dog+1\n",
    "        print(f\"Error processing {img_name}: {e}\")\n",
    "\n",
    "# Check the result\n",
    "if dog_images:\n",
    "    print(dog_images[0])\n",
    "else:\n",
    "    print(\"No valid images were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e454a7-54f5-4d33-85de-d0014956bb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(faults_dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc009d15-186e-4d41-b29e-c03da39967a6",
   "metadata": {},
   "source": [
    "Preparing data : (training and testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5bb5760-6edb-42f6-a7ca-719e66927d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming `cat_images` and `dog_images` contain normalized images\n",
    "cat_labels = [0] * len(cat_images)  # Label all cats as 0\n",
    "dog_labels = [1] * len(dog_images)  # Label all dogs as 1\n",
    "\n",
    "# Combine images and labels\n",
    "images = np.array(cat_images + dog_images)  # Combine all images into one array\n",
    "labels = np.array(cat_labels + dog_labels)  # Combine all labels into one array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0544fb0-b919-4e36-975f-86d6a566f812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (17498, 128, 128, 3), Validation data: (5025, 128, 128, 3), Test data: (2475, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further split temp data into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"Training data: {X_train.shape}, Validation data: {X_val.shape}, Test data: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f4754-7285-4aba-afde-45d02f4cc2e4",
   "metadata": {},
   "source": [
    "model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2a93506-67eb-4b5d-b5c9-d345b52f5d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madhu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57600</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,372,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57600\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m7,372,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,392,449</span> (28.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,392,449\u001b[0m (28.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,392,449</span> (28.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,392,449\u001b[0m (28.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),  # Input shape should match your normalized images\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Regularization to prevent overfitting\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41a24c6c-f6d0-4b7c-b317-81fb550b09e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 280ms/step - accuracy: 0.7240 - loss: 0.5465 - val_accuracy: 0.7827 - val_loss: 0.4729\n",
      "Epoch 2/5\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 269ms/step - accuracy: 0.8015 - loss: 0.4321 - val_accuracy: 0.7733 - val_loss: 0.4763\n",
      "Epoch 3/5\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 269ms/step - accuracy: 0.8462 - loss: 0.3588 - val_accuracy: 0.7958 - val_loss: 0.4582\n",
      "Epoch 4/5\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 268ms/step - accuracy: 0.8927 - loss: 0.2580 - val_accuracy: 0.7952 - val_loss: 0.4940\n",
      "Epoch 5/5\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 267ms/step - accuracy: 0.9384 - loss: 0.1653 - val_accuracy: 0.7940 - val_loss: 0.5522\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,  # Adjust the number of epochs based on performance\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f3312-f912-4488-bf05-1ab4de67f680",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2887245-1e83-4ca8-aedb-74c2dc72d460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7940 - loss: 0.5488\n",
      "Test Accuracy: 80.81%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c3c98d-27af-469c-80f8-58c392205fcc",
   "metadata": {},
   "source": [
    "model upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6615ac7-d65f-4dfb-8e52-f2456a4dc5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cat_dog_classifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a17ffc08-303c-4ea4-b7c0-3eee27bf1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_directory_path' with the path where you want to save the model\n",
    "model.save(r\"C:\\Users\\madhu\\OneDrive\\Documents\\Madhu's pri folder\\ML_projects\\Miniproject_part 2\\cat_dogs\\cat_dog_classifier.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06771244-3451-42d5-ad52-c013f2d7f407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
